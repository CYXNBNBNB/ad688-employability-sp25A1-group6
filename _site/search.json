[
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Import required libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\nLoad the dataset\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\nData Cleaning & Preprocessing\n\n1.1 Drop Unnecessary Columns\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col].fillna(df[col].median(), inplace=True)\n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col].fillna(\"Unknown\", inplace=True)\nfill_missing_values(df)\n\n\n\n\n\n\n\n\n/tmp/ipykernel_3100/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_3100/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_3100/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_3100/36208847.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(\"Unknown\", inplace=True)\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nprint(df.columns)\n\nIndex(['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES',\n       'SOURCES', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION',\n       'COMPANY_NAME', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS_NAME',\n       'MIN_EDULEVELS_NAME', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE',\n       'IS_INTERNSHIP', 'REMOTE_TYPE_NAME', 'LOCATION', 'CITY_NAME',\n       'COUNTY_NAME', 'MSA_NAME', 'STATE_NAME', 'COUNTY_NAME_OUTGOING',\n       'COUNTY_NAME_INCOMING', 'MSA_NAME_OUTGOING', 'MSA_NAME_INCOMING',\n       'TITLE_NAME', 'SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME',\n       'CERTIFICATIONS_NAME', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS_NAME',\n       'ONET_2019_NAME', 'CIP6_NAME', 'CIP4_NAME', 'CIP2_NAME',\n       'SOC_2021_5_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n       'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP_NAME',\n       'LOT_V6_CAREER_AREA_NAME', 'NAICS_2022_6_NAME'],\n      dtype='object')\n\n\n\nprint(df.isna().sum())\n\nLAST_UPDATED_DATE                     0\nPOSTED                                0\nEXPIRED                               0\nDURATION                              0\nSOURCE_TYPES                          0\nSOURCES                               0\nBODY                                  0\nMODELED_EXPIRED                       0\nMODELED_DURATION                      0\nCOMPANY_NAME                          0\nCOMPANY_IS_STAFFING                   0\nEDUCATION_LEVELS_NAME                 0\nMIN_EDULEVELS_NAME                    0\nEMPLOYMENT_TYPE_NAME                  0\nMIN_YEARS_EXPERIENCE                  0\nIS_INTERNSHIP                         0\nREMOTE_TYPE_NAME                      0\nLOCATION                              0\nCITY_NAME                             0\nCOUNTY_NAME                           0\nMSA_NAME                              0\nSTATE_NAME                            0\nCOUNTY_NAME_OUTGOING                  0\nCOUNTY_NAME_INCOMING                  0\nMSA_NAME_OUTGOING                     0\nMSA_NAME_INCOMING                     0\nTITLE_NAME                            0\nSKILLS_NAME                           0\nSPECIALIZED_SKILLS_NAME               0\nCERTIFICATIONS_NAME                   0\nCOMMON_SKILLS_NAME                    0\nSOFTWARE_SKILLS_NAME                  0\nONET_2019_NAME                        0\nCIP6_NAME                             0\nCIP4_NAME                             0\nCIP2_NAME                             0\nSOC_2021_5_NAME                       0\nLOT_V6_SPECIALIZED_OCCUPATION_NAME    0\nLOT_V6_OCCUPATION_NAME                0\nLOT_V6_OCCUPATION_GROUP_NAME          0\nLOT_V6_CAREER_AREA_NAME               0\nNAICS_2022_6_NAME                     0\ndtype: int64\n\n\n\nExploratory Data Analysis (EDA)"
  },
  {
    "objectID": "index.html#data-analysis",
    "href": "index.html#data-analysis",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Data Analysis",
    "text": "Data Analysis"
  },
  {
    "objectID": "index.html#career-strategy",
    "href": "index.html#career-strategy",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Career Strategy",
    "text": "Career Strategy"
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#salary-trends-in-data-science-2024",
    "href": "research_introduction.html#salary-trends-in-data-science-2024",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#expected-findings",
    "href": "research_introduction.html#expected-findings",
    "title": "Research Introduction",
    "section": "Expected Findings",
    "text": "Expected Findings\nThrough this research, we anticipate identifying key patterns in data science salaries, such as:\n\nAn increase in salaries for AI and machine learning specialists due to growing demand.\nPotential stagnation or decline in entry-level data science salaries due to an influx of new professionals entering the field.\nA widening salary gap between regions due to remote work policies and cost-of-living differences.\nIndustry-specific salary trends, where certain sectors may offer higher compensation based on their reliance on data-driven insights."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\n# Load dataset\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\nData Cleaning & Preprocessing 1.1 Drop Unnecessary Columns\n\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col].fillna(df[col].median(), inplace=True)\n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col].fillna(\"Unknown\", inplace=True)\nfill_missing_values(df)\n\n\n\n\n\n\n\n\n/tmp/ipykernel_6306/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_6306/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_6306/36208847.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(df[col].median(), inplace=True)\n/tmp/ipykernel_6306/36208847.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df[col].fillna(\"Unknown\", inplace=True)\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nExploratory Data Analysis (EDA)"
  }
]