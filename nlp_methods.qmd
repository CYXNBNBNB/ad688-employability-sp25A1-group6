---
title: "NLP Methods"
date-modified: today
date-format: long

#bibliography: references_analysis.bib
csl: csl/econometrica.csl
#nocite: '@*'  #show all references
format: 
  html:
    toc: true
    number-sections: true
    df-print: paged
    code-fold: true

execute:
  eval: false #false 不运行  true 运行
  echo: true  #显示代码

---
```{python}
import pandas as pd
import plotly.express as px
import plotly.io as pio
pio.renderers.default = "vscode"
from pyspark.sql import SparkSession
from pyspark.sql.functions import split, explode, col, regexp_replace, transform, isnan

spark = SparkSession.builder.appName("LightcastCleanedData").getOrCreate()

# 重新加载处理后的数据
df_cleaned = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").csv("data/lightcast_cleaned.csv")

# 查看数据结构和样本
df_cleaned.show(5)
```


用 Pandas + scikit-learn 处理, 得到了 TF-IDF 特征矩阵 X_tfidf 和对应文本在 body_df["BODY"] 中
```{python}
# 转换为 Pandas DataFrame，只取 BODY 列
body_df = df_cleaned.select("BODY").dropna().toPandas()

# 清理文本（可选）
body_df["BODY"] = body_df["BODY"].str.replace(r'\n|\r', ' ', regex=True)

# TF-IDF 提取
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
X_tfidf = tfidf_vectorizer.fit_transform(body_df["BODY"])

```




第一步：用 KMeans 聚类 TF-IDF 特征
```{python}
from sklearn.cluster import KMeans

# 聚成 k 类（你可以调整 n_clusters）
k = 4
kmeans = KMeans(n_clusters=k, random_state=42)
clusters = kmeans.fit_predict(X_tfidf)

# 把聚类结果加到原 DataFrame 中
body_df["cluster"] = clusters
```

 第二步：生成每个聚类的词云
```{python}
from sklearn.cluster import KMeans

# 聚成 k 类（你可以调整 n_clusters）
k = 4
kmeans = KMeans(n_clusters=k, random_state=42)
clusters = kmeans.fit_predict(X_tfidf)

# 把聚类结果加到原 DataFrame 中
body_df["cluster"] = clusters

from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np

# 获取词汇表
terms = tfidf_vectorizer.get_feature_names_out()

# 获取每个聚类中心的前关键词
order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]

import os

# 创建目录（如果不存在）
output_dir = "images/wordcloud"
os.makedirs(output_dir, exist_ok=True)

for i in range(k):
    print(f"生成第 {i} 类的词云...")

    top_terms = [terms[ind] for ind in order_centroids[i, :40]]
    weights = {term: kmeans.cluster_centers_[i][terms.tolist().index(term)] for term in top_terms}

    wordcloud = WordCloud(
        background_color='white',
        width=1600,
        height=800,
        max_font_size=300,
        prefer_horizontal=0.9
    ).generate_from_frequencies(weights)

    plt.figure(figsize=(16, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Cluster {i} Top Terms", fontsize=20)

    # 保存图像到指定目录
    output_path = os.path.join(output_dir, f"cluster_{i}_wordcloud.png")
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()
```

![Cluster 0 Wordcloud](images/wordcloud/cluster_0_wordcloud.png)
![Cluster 1 Wordcloud](images/wordcloud/cluster_1_wordcloud.png)
![Cluster 2 Wordcloud](images/wordcloud/cluster_2_wordcloud.png)
![Cluster 3 Wordcloud](images/wordcloud/cluster_3_wordcloud.png)


第三步（可选）：查看每一类的职位数量分布
```{python}
import plotly.express as px

fig = px.histogram(body_df, x="cluster", nbins=k, title="Distribution of jobs by theme (cluster)")
fig.write_html("./images/jobs_by_theme.html")
fig.show()

```

<iframe src="images/jobs_by_theme.html" width="100%" height="600"></iframe>


使用 TF-IDF 特征训练分类模型（SVM & Naive Bayes）
```{python}
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# 使用 cluster 作为分类目标
y = body_df["cluster"]

# 拆分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# 1️⃣ 训练 Naive Bayes 分类器
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)

# 2️⃣ 训练 SVM 分类器
svm_model = LinearSVC()
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)

# 评估：Naive Bayes
print("\n🔍 Naive Bayes :")
print(classification_report(y_test, y_pred_nb))

# 评估：SVM
print("\n🔍 SVM :")
print(classification_report(y_test, y_pred_svm))

# 混淆矩阵（SVM）
cm = confusion_matrix(y_test, y_pred_svm)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(k), yticklabels=range(k))
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("SVM confusion matrix")
plt.show()
```

你将看到两个模型的分类性能指标（precision, recall, f1-score）
混淆矩阵可以看出哪些聚类易混淆
如果性能不错，说明你提取的 TF-IDF 特征已经非常有区分度了




关键词热度可视化（最常见词条分析） 根据 词频（term frequency） 排名前 N 的词
```{python}
import numpy as np
import pandas as pd
import plotly.express as px

# 提取 TF-IDF 的词汇和矩阵
terms = tfidf_vectorizer.get_feature_names_out()
tfidf_matrix = X_tfidf.toarray()

# 🔹 方式一：按词频排序
term_frequencies = tfidf_matrix.sum(axis=0)
freq_df = pd.DataFrame({'term': terms, 'frequency': term_frequencies})
freq_df = freq_df.sort_values(by='frequency', ascending=False).head(30)

# 可视化：词频
fig1 = px.bar(freq_df, x='term', y='frequency', title="📈 Top 30 high-frequency words (by word frequency)", text_auto='.2s')
fig1.update_layout(xaxis_tickangle=-45)
fig.write_html("./images/Top30_high_frequency.html")
fig1.show()
```

<iframe src="images/Top30_high_frequency.html" width="100%" height="600"></iframe>
