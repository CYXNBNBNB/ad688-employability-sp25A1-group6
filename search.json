[
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport plotly.express as px\n\n# Load dataset\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")"
  },
  {
    "objectID": "data_analysis.html#data-cleaning-preprocessing",
    "href": "data_analysis.html#data-cleaning-preprocessing",
    "title": "Data Analysis",
    "section": "1 Data Cleaning & Preprocessing",
    "text": "1 Data Cleaning & Preprocessing\n\n1.1 Drop Unnecessary Columns\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\n\nCode\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n\n\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nCode\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n\n\n\n\nThe picture is missing.\n\n\n\n\nCode\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col] = df[col].fillna(df[col].median()) \n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col] = df[col].fillna(\"Unknown\")  \n    return df\n\nfill_missing_values(df)\n\n\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\n\nCode\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "data_analysis.html#exploratory-data-analysis-eda",
    "href": "data_analysis.html#exploratory-data-analysis-eda",
    "title": "Data Analysis",
    "section": "2 Exploratory Data Analysis (EDA)",
    "text": "2 Exploratory Data Analysis (EDA)\n\n2.1 1. Comparison of salary between remote and on-site work (box chart)\nFirst clean up REMOTE_TYPE_NAME, split all data into field, remote, and hybrid, and then plot.\nConvert values to string and clean unnecessary characters\n\n\nCode\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n\n### Standardize Remote Work Types\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n    \"None\": \"On-Site\",  \n    \"Not Remote\": \"On-Site\",\n    \"Hybrid Remote\": \"Hybrid\",\n    \"Remote\": \"Remote\"\n})\n\n\nRemove invalid values (numbers and locations)\n\n\nCode\nvalid_remote_types = [\"On-Site\", \"Hybrid\", \"Remote\"]\ndf = df[df[\"REMOTE_TYPE_NAME\"].isin(valid_remote_types)]\n\n\n\n\nCode\nfig = px.box(df, x=\"REMOTE_TYPE_NAME\", y=\"SALARY\",\n             title=\"Salary Comparison: Remote vs. On-Site Jobs\",\n             category_orders={\"REMOTE_TYPE_NAME\": [\"On-Site\", \"Hybrid\", \"Remote\"]},\n             labels={\"REMOTE_TYPE_NAME\": \"Job Type\", \"SALARY\": \"Salary ($)\"})\nfig.show()\n\n\n\n\n\nThe picture is missing.\n\n\n\n\n2.2 2. Salary by region (map)\nOriginally, the state names in “STATE_NAME” were all full names, so abbreviate them before drawing them\nConvert full state names to abbreviations\n\n\nCode\nimport us\ndf[\"STATE_NAME\"] = df[\"STATE_NAME\"].apply(lambda x: us.states.lookup(x).abbr if pd.notna(x) else x)\n\n\nVerify conversion\n\n\nCode\nprint(df[\"STATE_NAME\"].unique())  # Should now contain abbreviations like 'CA', 'TX', 'ME'\n\nfig = px.choropleth(df, \n                    locations=\"STATE_NAME\", \n                    locationmode=\"USA-states\",\n                    color=\"SALARY\", \n                    hover_name=\"STATE_NAME\",\n                    scope=\"usa\", \n                    title=\"Average Salary by State\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={\"SALARY\": \"Average Salary ($)\"})\n\nfig.show()\n\n\n\n\n\nThe picture is missing.\n\n\n\n\n2.3 3. The highest paying job\n\n\nCode\nfig = px.bar(df.groupby(\"LIGHTCAST_SECTORS_NAME\")[\"SALARY\"].mean().sort_values(ascending=False).head(10),\n             title=\"Top 10 Industries with Highest Salaries\",\n             labels={\"LIGHTCAST_SECTORS_NAME\": \"Industry\", \"SALARY\": \"Salary ($)\"})\nfig.show()\n\n\n\n\n\nThe picture is missing.\n\n\n\n\n2.4 4. Salary comparison between AI and non-AI positions\nFirst define in LIGHTCAST_SECTORS_NAME what is an AI job and what is not an AI job.\nDefine AI-related keywords based on LIGHTCAST_SECTORS_NAME\n\n\nCode\nai_keywords = [\n    \"Artificial Intelligence\", \"Machine Learning\", \"Data Science\",\n    \"Cybersecurity\", \"Computational Science\", \"Deep Learning\",\n    \"Data Privacy\", \"Computer Vision\", \"Natural Language Processing\",\n    \"Big Data\", \"Cloud Computing\", \"Quantum Computing\", \"Robotics\"\n]\n\n\nClassify AI-related vs. Non-AI industries\n\n\nCode\ndf[\"AI_RELATED\"] = df[\"LIGHTCAST_SECTORS_NAME\"].apply(\n    lambda x: \"AI-related\" if any(keyword in str(x) for keyword in ai_keywords) else \"Non-AI\"\n)\n\n# Show counts of AI vs. Non-AI jobs\nprint(df[\"AI_RELATED\"].value_counts())\n\n\n\n\nCode\nfig = px.box(df, x=\"AI_RELATED\", y=\"SALARY\",\n             title=\"AI-related vs. Non-AI Industries Salary Comparison\",\n             labels={\"AI_RELATED\": \"Industry Type\", \"SALARY\": \"Salary ($)\"},\n             color=\"AI_RELATED\")\n\nfig.show()\n\n\n\n\n\nThe picture is missing."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Import required libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\nLoad the dataset\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\nData Cleaning & Preprocessing\n\n1.1 Drop Unnecessary Columns\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n#plt.savefig(\"./images/missing_data.png\")  ##save the pic\n\n\n\n\n\n\n\n\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col] = df[col].fillna(df[col].median()) \n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col] = df[col].fillna(\"Unknown\")  \n    return df\n\nfill_missing_values(df)\n\n\n\n\n\n\n\n\nLAST_UPDATED_DATE\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nBODY\nMODELED_EXPIRED\nMODELED_DURATION\nCOMPANY_NAME\n...\nONET_2019_NAME\nCIP6_NAME\nCIP4_NAME\nCIP2_NAME\nSOC_2021_5_NAME\nLOT_V6_SPECIALIZED_OCCUPATION_NAME\nLOT_V6_OCCUPATION_NAME\nLOT_V6_OCCUPATION_GROUP_NAME\nLOT_V6_CAREER_AREA_NAME\nNAICS_2022_6_NAME\n\n\n\n\n0\n2024-09-06\n2024-06-02\n2024-06-08\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...\n2024-06-08\n6.0\nMurphy USA\n...\nBusiness Intelligence Analysts\n[\\n \"Economics, General\",\\n \"Mathematics, Ge...\n[\\n \"Economics\",\\n \"Mathematics\"\\n]\n[\\n \"Social Sciences\",\\n \"Mathematics and St...\nData Scientists\nGeneral ERP Analyst / Consultant\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nAutomotive Parts and Accessories Retailers\n\n\n1\n2024-08-02\n2024-06-02\n2024-08-01\n18.0\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\nOracle Consultant - Reports (3592)\\n\\nat SMX i...\n2024-08-01\n16.0\nSmx Corporation Limited\n...\nBusiness Intelligence Analysts\n[]\n[]\n[]\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nTemporary Help Services\n\n\n2\n2024-09-06\n2024-06-02\n2024-07-07\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\nTaking care of people is at the heart of every...\n2024-06-10\n8.0\nSedgwick\n...\nBusiness Intelligence Analysts\n[]\n[]\n[]\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nClaims Adjusting\n\n\n3\n2024-09-06\n2024-06-02\n2024-07-20\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\nAbout this role:\\n\\nWells Fargo is looking for...\n2024-06-12\n10.0\nWells Fargo\n...\nBusiness Intelligence Analysts\n[]\n[]\n[]\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nCommercial Banking\n\n\n4\n2024-06-19\n2024-06-02\n2024-06-17\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\nComisiones de $1000 - $3000 por semana... Comi...\n2024-06-17\n15.0\nUnclassified\n...\nBusiness Intelligence Analysts\n[]\n[]\n[]\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nUnclassified Industry\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n72471\n2024-09-06\n2024-08-16\n2024-08-31\n15.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\nTEKsystems\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\...\n2024-08-31\n15.0\nTEKsystems\n...\nBusiness Intelligence Analysts\n[\\n \"Business/Commerce, General\"\\n]\n[\\n \"Business/Commerce, General\"\\n]\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nCustom Computer Programming Services\n\n\n72472\n2024-10-21\n2024-08-16\nUnknown\n18.0\n[\\n \"Company\",\\n \"Job Board\"\\n]\n[\\n \"myworkdayjobs.com\",\\n \"mass-veterans.jo...\nLead Enterprise Architect - SalesForce \\nLead ...\n2024-09-13\n28.0\nWolters Kluwer\n...\nBusiness Intelligence Analysts\n[\\n \"Business Administration and Management, ...\n[\\n \"Business Administration, Management and ...\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nEnterprise Architect\nComputer Systems Engineer / Architect\nNetwork and Systems Engineering\nInformation Technology and Computer Science\nBook Publishers\n\n\n72473\n2024-10-16\n2024-08-16\n2024-09-22\n37.0\n[\\n \"Job Board\",\\n \"Company\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\nVolt\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\n in\\n...\n2024-08-31\n15.0\nVolt\n...\nBusiness Intelligence Analysts\n[\\n \"Data Analytics, General\",\\n \"Statistics...\n[\\n \"Data Analytics\",\\n \"Statistics\",\\n \"Co...\n[\\n \"Multi/Interdisciplinary Studies\",\\n \"Ma...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nEmployment Placement Agencies\n\n\n72474\n2024-10-16\n2024-08-16\n2024-10-15\n18.0\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\nData Analyst\\n\\nat Consolidated Communications...\n2024-09-08\n23.0\nConsolidated Communications Enterprise Service...\n...\nBusiness Intelligence Analysts\n[\\n \"Business/Commerce, General\",\\n \"Busines...\n[\\n \"Business/Commerce, General\",\\n \"Busines...\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nAll Other Telecommunications\n\n\n72475\n2024-10-09\n2024-08-16\n2024-08-22\n6.0\n[\\n \"Job Board\"\\n]\n[\\n \"dice.com\"\\n]\nOracle Fusion Analytics Warehouse (FAW) HCM Le...\n2024-08-22\n6.0\nLorven Technologies\n...\nBusiness Intelligence Analysts\n[\\n \"Computer Science\"\\n]\n[\\n \"Computer Science\"\\n]\n[\\n \"Computer and Information Sciences and Su...\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nComputer Systems Design Services\n\n\n\n\n72476 rows × 42 columns\n\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nExploratory Data Analysis (EDA)\nComparison of salary between remote and on-site work (box chart)\n\nFirst clean up REMOTE_TYPE_NAME, split all data into field, remote, and hybrid, and then plot.\n\n#Convert values to string and clean unnecessary characters\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n\n### Standardize Remote Work Types\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n    \"None\": \"On-Site\",  \n    \"Not Remote\": \"On-Site\",\n    \"Hybrid Remote\": \"Hybrid\",\n    \"Remote\": \"Remote\"\n})\n\n/tmp/ipykernel_4163/2955443620.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n/tmp/ipykernel_4163/2955443620.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n\n\n\n#Remove invalid values (numbers and locations)\nvalid_remote_types = [\"On-Site\", \"Hybrid\", \"Remote\"]\ndf = df[df[\"REMOTE_TYPE_NAME\"].isin(valid_remote_types)]\n\n\nimport plotly.express as px\n\nfig = px.box(df, x=\"REMOTE_TYPE_NAME\", y=\"SALARY\",\n             title=\"Salary Comparison: Remote vs. On-Site Jobs\",\n             category_orders={\"REMOTE_TYPE_NAME\": [\"On-Site\", \"Hybrid\", \"Remote\"]},\n             labels={\"REMOTE_TYPE_NAME\": \"Job Type\", \"SALARY\": \"Salary ($)\"})\nfig.show()\nplt.savefig(\"./images/box_chart.png\")  ##save the pic\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[11], line 3\n      1 import plotly.express as px\n----&gt; 3 fig = px.box(df, x=\"REMOTE_TYPE_NAME\", y=\"SALARY\",\n      4              title=\"Salary Comparison: Remote vs. On-Site Jobs\",\n      5              category_orders={\"REMOTE_TYPE_NAME\": [\"On-Site\", \"Hybrid\", \"Remote\"]},\n      6              labels={\"REMOTE_TYPE_NAME\": \"Job Type\", \"SALARY\": \"Salary ($)\"})\n      7 fig.show()\n      8 plt.savefig(\"./images/box_chart.png\")  ##save the pic\n\nFile ~/ad688-employability-sp25A1-group6/.venv/lib/python3.12/site-packages/plotly/express/_chart_types.py:679, in box(data_frame, x, y, color, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, orientation, boxmode, log_x, log_y, range_x, range_y, points, notched, title, subtitle, template, width, height)\n    637 def box(\n    638     data_frame=None,\n    639     x=None,\n   (...)    668     height=None,\n    669 ) -&gt; go.Figure:\n    670     \"\"\"\n    671     In a box plot, rows of `data_frame` are grouped together into a\n    672     box-and-whisker mark to visualize their distribution.\n   (...)    677     range (IQR: Q3-Q1), see \"points\" for other options.\n    678     \"\"\"\n--&gt; 679     return make_figure(\n    680         args=locals(),\n    681         constructor=go.Box,\n    682         trace_patch=dict(boxpoints=points, notched=notched, x0=\" \", y0=\" \"),\n    683         layout_patch=dict(boxmode=boxmode),\n    684     )\n\nFile ~/ad688-employability-sp25A1-group6/.venv/lib/python3.12/site-packages/plotly/express/_core.py:2477, in make_figure(args, constructor, trace_patch, layout_patch)\n   2474 layout_patch = layout_patch or {}\n   2475 apply_default_cascade(args)\n-&gt; 2477 args = build_dataframe(args, constructor)\n   2478 if constructor in [go.Treemap, go.Sunburst, go.Icicle] and args[\"path\"] is not None:\n   2479     args = process_dataframe_hierarchy(args)\n\nFile ~/ad688-employability-sp25A1-group6/.venv/lib/python3.12/site-packages/plotly/express/_core.py:1727, in build_dataframe(args, constructor)\n   1724     args[\"color\"] = None\n   1725 # now that things have been prepped, we do the systematic rewriting of `args`\n-&gt; 1727 df_output, wide_id_vars = process_args_into_dataframe(\n   1728     args,\n   1729     wide_mode,\n   1730     var_name,\n   1731     value_name,\n   1732     is_pd_like,\n   1733     native_namespace,\n   1734 )\n   1735 df_output: nw.DataFrame\n   1736 # now that `df_output` exists and `args` contains only references, we complete\n   1737 # the special-case and wide-mode handling by further rewriting args and/or mutating\n   1738 # df_output\n\nFile ~/ad688-employability-sp25A1-group6/.venv/lib/python3.12/site-packages/plotly/express/_core.py:1328, in process_args_into_dataframe(args, wide_mode, var_name, value_name, is_pd_like, native_namespace)\n   1326         if argument == \"index\":\n   1327             err_msg += \"\\n To use the index, pass it in directly as `df.index`.\"\n-&gt; 1328         raise ValueError(err_msg)\n   1329 elif length and (actual_len := len(df_input)) != length:\n   1330     raise ValueError(\n   1331         \"All arguments should have the same length. \"\n   1332         \"The length of column argument `df[%s]` is %d, whereas the \"\n   (...)   1339         )\n   1340     )\n\nValueError: Value of 'y' is not the name of a column in 'data_frame'. Expected one of ['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY_NAME', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS_NAME', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'REMOTE_TYPE_NAME', 'LOCATION', 'CITY_NAME', 'COUNTY_NAME', 'MSA_NAME', 'STATE_NAME', 'COUNTY_NAME_OUTGOING', 'COUNTY_NAME_INCOMING', 'MSA_NAME_OUTGOING', 'MSA_NAME_INCOMING', 'TITLE_NAME', 'SKILLS_NAME', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS_NAME', 'ONET_2019_NAME', 'CIP6_NAME', 'CIP4_NAME', 'CIP2_NAME', 'SOC_2021_5_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA_NAME', 'NAICS_2022_6_NAME'] but received: SALARY\n\n\n\n\nSalary by region (map)\n\nOriginally, the state names in “STATE_NAME” were all full names, so abbreviate them before drawing them\n\n#Convert full state names to abbreviations\nimport us\ndf[\"STATE_NAME\"] = df[\"STATE_NAME\"].apply(lambda x: us.states.lookup(x).abbr if pd.notna(x) else x)\n\n\n#Verify conversion\nprint(df[\"STATE_NAME\"].unique())  # Should now contain abbreviations like 'CA', 'TX', 'ME'\n\nimport plotly.express as px\n\nfig = px.choropleth(df, \n                    locations=\"STATE_NAME\", \n                    locationmode=\"USA-states\",\n                    color=\"SALARY\", \n                    hover_name=\"STATE_NAME\",\n                    scope=\"usa\", \n                    title=\"Average Salary by State\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={\"SALARY\": \"Average Salary ($)\"})\n\nfig.show()\nplt.savefig(\"./images/map.png\")  ##save the pic\n\n\nThe highest paying job\n\n\nfig = px.bar(df.groupby(\"LIGHTCAST_SECTORS_NAME\")[\"SALARY\"].mean().sort_values(ascending=False).head(10),\n             title=\"Top 10 Industries with Highest Salaries\",\n             labels={\"LIGHTCAST_SECTORS_NAME\": \"Industry\", \"SALARY\": \"Salary ($)\"})\nfig.show()\nplt.savefig(\"./images/highest_paying_job.png\")  ##save the pic\n\n\nSalary comparison between AI and non-AI positions\n\nFirst define in LIGHTCAST_SECTORS_NAME what is an AI job and what is not an AI job.\n\n#Define AI-related keywords based on LIGHTCAST_SECTORS_NAME\nai_keywords = [\n    \"Artificial Intelligence\", \"Machine Learning\", \"Data Science\",\n    \"Cybersecurity\", \"Computational Science\", \"Deep Learning\",\n    \"Data Privacy\", \"Computer Vision\", \"Natural Language Processing\",\n    \"Big Data\", \"Cloud Computing\", \"Quantum Computing\", \"Robotics\"\n]\n\n\n#Classify AI-related vs. Non-AI industries\ndf[\"AI_RELATED\"] = df[\"LIGHTCAST_SECTORS_NAME\"].apply(\n    lambda x: \"AI-related\" if any(keyword in str(x) for keyword in ai_keywords) else \"Non-AI\"\n)\n\n# Show counts of AI vs. Non-AI jobs\nprint(df[\"AI_RELATED\"].value_counts())\n\n\nimport plotly.express as px\n\nfig = px.box(df, x=\"AI_RELATED\", y=\"SALARY\",\n             title=\"AI-related vs. Non-AI Industries Salary Comparison\",\n             labels={\"AI_RELATED\": \"Industry Type\", \"SALARY\": \"Salary ($)\"},\n             color=\"AI_RELATED\")\n\nfig.show()\nplt.savefig(\"./images/salary_comparision.png\")  ##save the pic"
  },
  {
    "objectID": "index.html#data-analysis",
    "href": "index.html#data-analysis",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Data Analysis",
    "text": "Data Analysis"
  },
  {
    "objectID": "index.html#career-strategy",
    "href": "index.html#career-strategy",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Career Strategy",
    "text": "Career Strategy"
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#salary-trends-in-data-science-2024",
    "href": "research_introduction.html#salary-trends-in-data-science-2024",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#expected-findings",
    "href": "research_introduction.html#expected-findings",
    "title": "Research Introduction",
    "section": "Expected Findings",
    "text": "Expected Findings\nThrough this research, we anticipate identifying key patterns in data science salaries, such as:\n\nAn increase in salaries for AI and machine learning specialists due to growing demand.\nPotential stagnation or decline in entry-level data science salaries due to an influx of new professionals entering the field.\nA widening salary gap between regions due to remote work policies and cost-of-living differences.\nIndustry-specific salary trends, where certain sectors may offer higher compensation based on their reliance on data-driven insights."
  }
]