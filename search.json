[
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport plotly.express as px\n\n# Load dataset\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")"
  },
  {
    "objectID": "data_analysis.html#data-cleaning-preprocessing",
    "href": "data_analysis.html#data-cleaning-preprocessing",
    "title": "Data Analysis",
    "section": "1 Data Cleaning & Preprocessing",
    "text": "1 Data Cleaning & Preprocessing\n\n1.1 Drop Unnecessary Columns\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\n\nCode\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n\n\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nCode\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n\n\n\n\nCode\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col] = df[col].fillna(df[col].median()) \n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col] = df[col].fillna(\"Unknown\")  \n    return df\n\nfill_missing_values(df)\n\n\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\n\nCode\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "data_analysis.html#exploratory-data-analysis-eda",
    "href": "data_analysis.html#exploratory-data-analysis-eda",
    "title": "Data Analysis",
    "section": "2 Exploratory Data Analysis (EDA)",
    "text": "2 Exploratory Data Analysis (EDA)\n\n2.1 Comparison of salary between remote and on-site work (box chart)\nFirst clean up REMOTE_TYPE_NAME, split all data into field, remote, and hybrid, and then plot.\nConvert values to string and clean unnecessary characters\n\n\nCode\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n\n### Standardize Remote Work Types\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n    \"None\": \"On-Site\",  \n    \"Not Remote\": \"On-Site\",\n    \"Hybrid Remote\": \"Hybrid\",\n    \"Remote\": \"Remote\"\n})\n\n\nRemove invalid values (numbers and locations)\n\n\nCode\nvalid_remote_types = [\"On-Site\", \"Hybrid\", \"Remote\"]\ndf = df[df[\"REMOTE_TYPE_NAME\"].isin(valid_remote_types)]\n\n\n\n\nCode\nfig = px.box(df, x=\"REMOTE_TYPE_NAME\", y=\"SALARY\",\n             title=\"Salary Comparison: Remote vs. On-Site Jobs\",\n             category_orders={\"REMOTE_TYPE_NAME\": [\"On-Site\", \"Hybrid\", \"Remote\"]},\n             labels={\"REMOTE_TYPE_NAME\": \"Job Type\", \"SALARY\": \"Salary ($)\"})\nfig.show()\n\n\n\n\n\nFigure 1.1\n\n\n\n\n2.2 Salary by region (map)\nOriginally, the state names in “STATE_NAME” were all full names, so abbreviate them before drawing them\nConvert full state names to abbreviations\n\n\nCode\nimport us\ndf[\"STATE_NAME\"] = df[\"STATE_NAME\"].apply(lambda x: us.states.lookup(x).abbr if pd.notna(x) else x)\n\n\nVerify conversion\n\n\nCode\nprint(df[\"STATE_NAME\"].unique())  # Should now contain abbreviations like 'CA', 'TX', 'ME'\n\nfig = px.choropleth(df, \n                    locations=\"STATE_NAME\", \n                    locationmode=\"USA-states\",\n                    color=\"SALARY\", \n                    hover_name=\"STATE_NAME\",\n                    scope=\"usa\", \n                    title=\"Average Salary by State\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={\"SALARY\": \"Average Salary ($)\"})\n\nfig.show()\n\n\n\n\n\nFigure 1.2\n\n\n\n\n2.3 The highest paying job\n\n\nCode\nfig = px.bar(df.groupby(\"LIGHTCAST_SECTORS_NAME\")[\"SALARY\"].mean().sort_values(ascending=False).head(10),\n             title=\"Top 10 Industries with Highest Salaries\",\n             labels={\"LIGHTCAST_SECTORS_NAME\": \"Industry\", \"SALARY\": \"Salary ($)\"})\nfig.show()\n\n\n\n\n\nFigure 1.3\n\n\n\n\n2.4 Salary comparison between AI and non-AI positions\nFirst define in LIGHTCAST_SECTORS_NAME what is an AI job and what is not an AI job.\nDefine AI-related keywords based on LIGHTCAST_SECTORS_NAME\n\n\nCode\nai_keywords = [\n    \"Artificial Intelligence\", \"Machine Learning\", \"Data Science\",\n    \"Cybersecurity\", \"Computational Science\", \"Deep Learning\",\n    \"Data Privacy\", \"Computer Vision\", \"Natural Language Processing\",\n    \"Big Data\", \"Cloud Computing\", \"Quantum Computing\", \"Robotics\"\n]\n\n\nClassify AI-related vs. Non-AI industries\n\n\nCode\ndf[\"AI_RELATED\"] = df[\"LIGHTCAST_SECTORS_NAME\"].apply(\n    lambda x: \"AI-related\" if any(keyword in str(x) for keyword in ai_keywords) else \"Non-AI\"\n)\n\n# Show counts of AI vs. Non-AI jobs\nprint(df[\"AI_RELATED\"].value_counts())\n\n\n\n\nCode\nfig = px.box(df, x=\"AI_RELATED\", y=\"SALARY\",\n             title=\"AI-related vs. Non-AI Industries Salary Comparison\",\n             labels={\"AI_RELATED\": \"Industry Type\", \"SALARY\": \"Salary ($)\"},\n             color=\"AI_RELATED\")\n\nfig.show()\n\n\n\n\n\nFigure 1.4"
  },
  {
    "objectID": "data_analysis_test.html",
    "href": "data_analysis_test.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Import required libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\nLoad the dataset\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\nData Cleaning & Preprocessing\n\n1.1 Drop Unnecessary Columns\nMany variables in the dataset has two columns, one is code name of the variable, and the other is the real name of the variable. We will delete all the columns with code name of the variables, since they are meaningless. For example, we have a job “Data analysts”, we do not need to know whether its code name is “10001”, or “A-001”, or something like this, because it’s useless and there’s no real significance to it, we can change these code names at will.\nAlso, columns like “LAST_UPDATED_TIMESTAMP”, duplicates the meaning of the other variable “LAST_UPDATED_DATE”. Since we basically only need to know the last update date, and don’t have to be specific to a moment in that day, we’ll remove such columns as well.\nWe remove redundant ONET/NAICS/SOC/LOR codes and tracking data to simplify our dataset. Keeping only the latest ONET_2019, NAICS_2022_6, SOC_2021_5, and LOT_V6 ensures that our analysis reflects current industry and occupational classifications.\n\ncolumns_to_drop = [\"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_SOURCES_INFO\",\n\"TITLE_RAW\", \"COMPANY\", \"COMPANY_RAW\", \"EDUCATION_LEVELS\", \"MIN_EDULEVELS\", \"MAX_EDULEVELS\",\n\"EMPLOYMENT_TYPE\", \"REMOTE_TYPE\", \"CITY\", \"COUNTY\", \"MSA\", \"STATE\", \"COUNTY_OUTGOING\",\n\"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\", \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\",\n\"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\", \"NAICS6_NAME\", \"TITLE\", \"TITLE_CLEAN\",\n\"SKILLS\", \"SPECIALIZED_SKILLS\", \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SOFTWARE_SKILLS\", \"ONET\", \"ONET_NAME\",\n\"ONET_2019\", \"CIP6\", \"CIP4\", \"CIP2\", \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\",\n\"SOC_2021_4\", \"SOC_2021_4_NAME\", \"SOC_2021_5\", \"LOT_CAREER_AREA\", \"LOT_CAREER_AREA_NAME\", \"LOT_OCCUPATION\",\n\"LOT_OCCUPATION_NAME\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_SPECIALIZED_OCCUPATION_NAME\", \"LOT_OCCUPATION_GROUP\",\n\"LOT_OCCUPATION_GROUP_NAME\", \"LOT_V6_SPECIALIZED_OCCUPATION\", \"LOT_V6_OCCUPATION\", \"LOT_V6_OCCUPATION_GROUP\",\n\"LOT_V6_CAREER_AREA\", \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_4\", \"SOC_4_NAME\", \"SOC_5\",\n\"SOC_5_NAME\", \"LIGHTCAST_SECTORS\", \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\",\n\"NAICS_2022_4\", \"NAICS_2022_4_NAME\", \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\"]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n1.2 Handle Missing Values\nWe use different strategies for missing values:\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Company Name) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n# Visualize missing data\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\n\nplt.savefig(\"./images/missing_data.png\")  ##save the pic\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Fill missing values\ndef fill_missing_values(df):\n    for col in df.select_dtypes(include=['number']).columns:\n        df[col] = df[col].fillna(df[col].median()) \n    for col in df.select_dtypes(exclude=['number']).columns:\n        df[col] = df[col].fillna(\"Unknown\")  \n    return df\n\nfill_missing_values(df)\n\n\n\n\n\n\n\n\nLAST_UPDATED_DATE\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nBODY\nMODELED_EXPIRED\nMODELED_DURATION\nCOMPANY_NAME\n...\nCIP6_NAME\nCIP4_NAME\nCIP2_NAME\nSOC_2021_5_NAME\nLOT_V6_SPECIALIZED_OCCUPATION_NAME\nLOT_V6_OCCUPATION_NAME\nLOT_V6_OCCUPATION_GROUP_NAME\nLOT_V6_CAREER_AREA_NAME\nLIGHTCAST_SECTORS_NAME\nNAICS_2022_6_NAME\n\n\n\n\n0\n2024-09-06\n2024-06-02\n2024-06-08\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...\n2024-06-08\n6.0\nMurphy USA\n...\n[\\n \"Economics, General\",\\n \"Mathematics, Ge...\n[\\n \"Economics\",\\n \"Mathematics\"\\n]\n[\\n \"Social Sciences\",\\n \"Mathematics and St...\nData Scientists\nGeneral ERP Analyst / Consultant\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\n[\\n \"Artificial Intelligence\"\\n]\nAutomotive Parts and Accessories Retailers\n\n\n1\n2024-08-02\n2024-06-02\n2024-08-01\n18.0\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\nOracle Consultant - Reports (3592)\\n\\nat SMX i...\n2024-08-01\n16.0\nSmx Corporation Limited\n...\n[]\n[]\n[]\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nUnknown\nTemporary Help Services\n\n\n2\n2024-09-06\n2024-06-02\n2024-07-07\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\nTaking care of people is at the heart of every...\n2024-06-10\n8.0\nSedgwick\n...\n[]\n[]\n[]\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nUnknown\nClaims Adjusting\n\n\n3\n2024-09-06\n2024-06-02\n2024-07-20\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\nAbout this role:\\n\\nWells Fargo is looking for...\n2024-06-12\n10.0\nWells Fargo\n...\n[]\n[]\n[]\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\n[\\n \"Data Privacy/Protection\"\\n]\nCommercial Banking\n\n\n4\n2024-06-19\n2024-06-02\n2024-06-17\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\nComisiones de $1000 - $3000 por semana... Comi...\n2024-06-17\n15.0\nUnclassified\n...\n[]\n[]\n[]\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nUnknown\nUnclassified Industry\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n72471\n2024-09-06\n2024-08-16\n2024-08-31\n15.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\nTEKsystems\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\...\n2024-08-31\n15.0\nTEKsystems\n...\n[\\n \"Business/Commerce, General\"\\n]\n[\\n \"Business/Commerce, General\"\\n]\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\n[\\n \"Artificial Intelligence\"\\n]\nCustom Computer Programming Services\n\n\n72472\n2024-10-21\n2024-08-16\nUnknown\n18.0\n[\\n \"Company\",\\n \"Job Board\"\\n]\n[\\n \"myworkdayjobs.com\",\\n \"mass-veterans.jo...\nLead Enterprise Architect - SalesForce \\nLead ...\n2024-09-13\n28.0\nWolters Kluwer\n...\n[\\n \"Business Administration and Management, ...\n[\\n \"Business Administration, Management and ...\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nEnterprise Architect\nComputer Systems Engineer / Architect\nNetwork and Systems Engineering\nInformation Technology and Computer Science\n[\\n \"Cybersecurity\"\\n]\nBook Publishers\n\n\n72473\n2024-10-16\n2024-08-16\n2024-09-22\n37.0\n[\\n \"Job Board\",\\n \"Company\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\nVolt\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\n in\\n...\n2024-08-31\n15.0\nVolt\n...\n[\\n \"Data Analytics, General\",\\n \"Statistics...\n[\\n \"Data Analytics\",\\n \"Statistics\",\\n \"Co...\n[\\n \"Multi/Interdisciplinary Studies\",\\n \"Ma...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nUnknown\nEmployment Placement Agencies\n\n\n72474\n2024-10-16\n2024-08-16\n2024-10-15\n18.0\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\nData Analyst\\n\\nat Consolidated Communications...\n2024-09-08\n23.0\nConsolidated Communications Enterprise Service...\n...\n[\\n \"Business/Commerce, General\",\\n \"Busines...\n[\\n \"Business/Commerce, General\",\\n \"Busines...\n[\\n \"Business, Management, Marketing, and Rel...\nData Scientists\nData Analyst\nData / Data Mining Analyst\nData Analysis and Mathematics\nInformation Technology and Computer Science\nUnknown\nAll Other Telecommunications\n\n\n72475\n2024-10-09\n2024-08-16\n2024-08-22\n6.0\n[\\n \"Job Board\"\\n]\n[\\n \"dice.com\"\\n]\nOracle Fusion Analytics Warehouse (FAW) HCM Le...\n2024-08-22\n6.0\nLorven Technologies\n...\n[\\n \"Computer Science\"\\n]\n[\\n \"Computer Science\"\\n]\n[\\n \"Computer and Information Sciences and Su...\nData Scientists\nOracle Consultant / Analyst\nBusiness Intelligence Analyst\nBusiness Intelligence\nInformation Technology and Computer Science\nUnknown\nComputer Systems Design Services\n\n\n\n\n72476 rows × 49 columns\n\n\n\n1.3 Remove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\ndf = df.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nExploratory Data Analysis (EDA)\nComparison of salary between remote and on-site work (box chart)\n\nFirst clean up REMOTE_TYPE_NAME, split all data into field, remote, and hybrid, and then plot.\n\n#Convert values to string and clean unnecessary characters\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n\n### Standardize Remote Work Types\ndf[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n    \"None\": \"On-Site\",  \n    \"Not Remote\": \"On-Site\",\n    \"Hybrid Remote\": \"Hybrid\",\n    \"Remote\": \"Remote\"\n})\n\n/tmp/ipykernel_6250/2955443620.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].astype(str).str.replace(r\"[\\[\\]']\", \"\", regex=True).str.strip()\n/tmp/ipykernel_6250/2955443620.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"REMOTE_TYPE_NAME\"] = df[\"REMOTE_TYPE_NAME\"].replace({\n\n\n\n#Remove invalid values (numbers and locations)\nvalid_remote_types = [\"On-Site\", \"Hybrid\", \"Remote\"]\ndf = df[df[\"REMOTE_TYPE_NAME\"].isin(valid_remote_types)]\n\n\nimport plotly.express as px\n\nfig = px.box(df, x=\"REMOTE_TYPE_NAME\", y=\"SALARY\",\n             title=\"Salary Comparison: Remote vs. On-Site Jobs\",\n             category_orders={\"REMOTE_TYPE_NAME\": [\"On-Site\", \"Hybrid\", \"Remote\"]},\n             labels={\"REMOTE_TYPE_NAME\": \"Job Type\", \"SALARY\": \"Salary ($)\"})\n\nfig.write_image(\"./images/box_chart.png\")  ##save the pic\n\nfig.show()\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\nSalary by region (map)\n\nOriginally, the state names in “STATE_NAME” were all full names, so abbreviate them before drawing them\n\n#Convert full state names to abbreviations\nimport us\ndf[\"STATE_NAME\"] = df[\"STATE_NAME\"].apply(\n    lambda x: us.states.lookup(x).abbr if pd.notna(x) and us.states.lookup(x) else x\n)\n\n\n#Verify conversion\nprint(df[\"STATE_NAME\"].unique())  # Should now contain abbreviations like 'CA', 'TX', 'ME'\n\nimport plotly.express as px\n\nfig = px.choropleth(df, \n                    locations=\"STATE_NAME\", \n                    locationmode=\"USA-states\",\n                    color=\"SALARY\", \n                    hover_name=\"STATE_NAME\",\n                    scope=\"usa\", \n                    title=\"Average Salary by State\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={\"SALARY\": \"Average Salary ($)\"})\n\nfig.write_image(\"./images/map.png\")  ##save the pic\n\nfig.show()\n\n['AR' 'ME' 'TX' 'AZ' 'CA' 'OH' 'NJ' 'NY' 'HI' 'GA' 'MI' 'MS' 'MA' 'AK'\n 'AL' 'IN' 'VA' 'SC' 'CO' 'NV' 'MN' 'OR' 'OK' 'NC' 'FL' 'WA' 'DE' 'IL'\n 'PA' 'KS' 'TN' 'Washington, D.C. (District of Columbia)' 'MD' 'ID' 'LA'\n 'CT' 'NE' 'MO' 'ND' 'UT' 'NH' 'WI' 'KY' 'RI' 'IA' 'SD' 'MT' 'NM' 'WY'\n 'WV' 'VT']\n\n\n                            \n                                            \n\n\n\nThe highest paying job\n\n\nfig = px.bar(df.groupby(\"LIGHTCAST_SECTORS_NAME\")[\"SALARY\"].mean().sort_values(ascending=False).head(10),\n             title=\"Top 10 Industries with Highest Salaries\",\n             labels={\"LIGHTCAST_SECTORS_NAME\": \"Industry\", \"SALARY\": \"Salary ($)\"})\n\nfig.write_image(\"./images/highest_paying_job.png\")  ##save the pic\n\nfig.show()\n\n                            \n                                            \n\n\n\nSalary comparison between AI and non-AI positions\n\nFirst define in LIGHTCAST_SECTORS_NAME what is an AI job and what is not an AI job.\n\n#Define AI-related keywords based on LIGHTCAST_SECTORS_NAME\nai_keywords = [\n    \"Artificial Intelligence\", \"Machine Learning\", \"Data Science\",\n    \"Cybersecurity\", \"Computational Science\", \"Deep Learning\",\n    \"Data Privacy\", \"Computer Vision\", \"Natural Language Processing\",\n    \"Big Data\", \"Cloud Computing\", \"Quantum Computing\", \"Robotics\"\n]\n\n\n#Classify AI-related vs. Non-AI industries\ndf[\"AI_RELATED\"] = df[\"LIGHTCAST_SECTORS_NAME\"].apply(\n    lambda x: \"AI-related\" if any(keyword in str(x) for keyword in ai_keywords) else \"Non-AI\"\n)\n\n# Show counts of AI vs. Non-AI jobs\nprint(df[\"AI_RELATED\"].value_counts())\n\nAI_RELATED\nNon-AI        52992\nAI-related    16208\nName: count, dtype: int64\n\n\n\nimport plotly.express as px\n\nfig = px.box(df, x=\"AI_RELATED\", y=\"SALARY\",\n             title=\"AI-related vs. Non-AI Industries Salary Comparison\",\n             labels={\"AI_RELATED\": \"Industry Type\", \"SALARY\": \"Salary ($)\"},\n             color=\"AI_RELATED\")\n\nfig.write_image(\"./images/salary_comparision.png\")  ##save the pic\n\nfig.show()"
  },
  {
    "objectID": "index.html#data-analysis",
    "href": "index.html#data-analysis",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Data Analysis",
    "text": "Data Analysis"
  },
  {
    "objectID": "index.html#career-strategy",
    "href": "index.html#career-strategy",
    "title": "Group 6    Job Market Analysis – 2024",
    "section": "Career Strategy",
    "text": "Career Strategy"
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#salary-trends-in-data-science-2024",
    "href": "research_introduction.html#salary-trends-in-data-science-2024",
    "title": "Research Introduction",
    "section": "",
    "text": "The field of data science continues to be one of the most lucrative and dynamic career paths in 2024. As businesses increasingly rely on data-driven decision-making, the demand for skilled data scientists has grown across industries, including technology, finance, healthcare, and e-commerce. However, salary trends in data science are influenced by a variety of factors, such as emerging technologies, economic conditions, geographic location, and skill specialization. This research aims to analyze salary patterns in data science in 2024, providing insights into compensation disparities and growth opportunities within the industry.\nSeveral key trends make this topic particularly relevant in 2024:\n\nAI and Automation Influence: The rapid advancement of AI and automation tools has shifted the skill demands in data science, leading to changes in salary structures for specialized roles such as AI engineers and machine learning researchers.\nRemote Work and Globalization: The continued rise of remote work has impacted salary expectations, with companies hiring from a broader talent pool across different geographical regions, leading to potential salary standardization or disparities.\nEconomic Factors: Economic conditions, including inflation and recession fears, have influenced hiring trends and salary negotiations in the tech sector, causing fluctuations in compensation levels.\nExperience and Specialization Impact: Salaries in data science vary significantly based on experience level and specialization ( deep learning, big data analytics, or cloud computing). Understanding these variations helps professionals navigate career growth strategies.\nIndustry-Specific Variations: Different industries offer varying compensation packages for data science roles, with sectors such as finance and healthcare often providing higher salaries compared to non-tech industries."
  },
  {
    "objectID": "research_introduction.html#expected-findings",
    "href": "research_introduction.html#expected-findings",
    "title": "Research Introduction",
    "section": "Expected Findings",
    "text": "Expected Findings\nThrough this research, we anticipate identifying key patterns in data science salaries, such as:\n\nAn increase in salaries for AI and machine learning specialists due to growing demand.\nPotential stagnation or decline in entry-level data science salaries due to an influx of new professionals entering the field.\nA widening salary gap between regions due to remote work policies and cost-of-living differences.\nIndustry-specific salary trends, where certain sectors may offer higher compensation based on their reliance on data-driven insights."
  }
]